{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting annotations: 100%|██████████| 323/323 [00:00<00:00, 909.78it/s]\n",
      "Converting annotations: 100%|██████████| 43/43 [00:00<00:00, 704.30it/s]\n",
      "Converting annotations: 100%|██████████| 121/121 [00:00<00:00, 661.05it/s]\n",
      "Converting annotations: 100%|██████████| 22/22 [00:00<00:00, 703.64it/s]\n",
      "Converting annotations: 100%|██████████| 82/82 [00:00<00:00, 645.41it/s]\n",
      "Converting annotations: 100%|██████████| 101/101 [00:00<00:00, 665.55it/s]\n",
      "Converting annotations: 100%|██████████| 17/17 [00:00<00:00, 459.45it/s]\n",
      "Converting annotations: 100%|██████████| 171/171 [00:00<00:00, 679.94it/s]\n",
      "Converting annotations: 100%|██████████| 52/52 [00:00<00:00, 702.74it/s]\n",
      "Converting annotations: 100%|██████████| 107/107 [00:00<00:00, 635.01it/s]\n",
      "Converting annotations: 100%|██████████| 67/67 [00:00<00:00, 656.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pycocotools import mask as maskUtils\n",
    "import cv2\n",
    "\n",
    "def rle2polygon(segmentation, h, w):\n",
    "    \"\"\"\n",
    "    将游程编码(RLE)或多边形分割数据转换为多边形坐标列表。\n",
    "    此功能对于处理图像数据集中的不同分割格式至关重要。\n",
    "\n",
    "    参数:\n",
    "        segmentation (dict or list): RLE或多边形分割数据。\n",
    "        h (int): 图像的高度。\n",
    "        w (int): 图像的宽度。\n",
    "\n",
    "    返回:\n",
    "        list: 表示为 [x1, y1, x2, y2, ..., xn, yn] 的多边形列表。\n",
    "\n",
    "    详细信息:\n",
    "    该函数首先检查分割是否为RLE格式。如果, 则将RLE解码为二进制掩码。\n",
    "    如果是多边形, 则先将其转换为RLE, 然后解码。\n",
    "    然后使用OpenCV查找轮廓(代表对象的边缘)并将这些轮廓近似为多边形。\n",
    "    \"\"\"\n",
    "    # Check if segmentation is in RLE format (dict)\n",
    "    if isinstance(segmentation, dict):\n",
    "        m = maskUtils.decode(segmentation)\n",
    "    else:\n",
    "        # Convert polygon segmentation to RLE first\n",
    "        rle = maskUtils.frPyObjects(segmentation, h, w)\n",
    "        compressed_rle = maskUtils.merge(rle)\n",
    "        m = maskUtils.decode(compressed_rle)\n",
    "\n",
    "    m[m > 0] = 255\n",
    "    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    polygons = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "        contour_approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        polygon = contour_approx.flatten().tolist()\n",
    "        polygons.append(polygon)\n",
    "    return polygons\n",
    "\n",
    "def crop_img(image_path, output_folder, dataset_name, annotation, adjusted_segmentation):\n",
    "    \"\"\"\n",
    "    根据预定义坐标裁剪图像, 并相应调整其分割标注。\n",
    "    此功能用于专注于图像及其相应注释的特定部分。\n",
    "\n",
    "    参数:\n",
    "        image_path (str): 源图像的路径。\n",
    "        output_folder (str): 裁剪图像将被保存的目录。\n",
    "        dataset_name (str): 用于命名输出文件的数据集名称。\n",
    "        annotation (dict): 图像的原始注释数据。\n",
    "        adjusted_segmentation (list): 转换为多边形坐标的分割数据。\n",
    "\n",
    "    返回:\n",
    "        tuple: 更新的注释，新图像高度和宽度。\n",
    "\n",
    "    详细信息:\n",
    "    此函数打开图像，根据预定义坐标进行裁剪，然后保存裁剪后的图像。\n",
    "    它还调整注释中的分割坐标，以匹配裁剪后图像的新尺寸。\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    width, height = image.size\n",
    "\n",
    "    # Define the coordinates for cropping\n",
    "    left = 390\n",
    "    right = width - 90\n",
    "    top = 55\n",
    "    bottom = height - 55\n",
    "\n",
    "    # Ensure coordinates are within the image dimensions\n",
    "    left = max(0, left)\n",
    "    right = min(width, right)\n",
    "    top = max(0, top)\n",
    "    bottom = min(height, bottom)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "\n",
    "    # Save the cropped image\n",
    "    image_filename = os.path.basename(image_path)\n",
    "    output_folder = output_folder + '\\images'\n",
    "\n",
    "    new_image_filename = dataset_name+'_'+image_filename\n",
    "    output_image_path = os.path.join(output_folder, new_image_filename)\n",
    "    cropped_image.save(output_image_path)\n",
    "\n",
    "    # Adjust the segmentation coordinates\n",
    "    new_segmentation = []\n",
    "    for segment in adjusted_segmentation:\n",
    "        adjusted_segment = []\n",
    "        for i in range(0, len(segment), 2):\n",
    "            x, y = segment[i], segment[i + 1]\n",
    "            # Adjusting the coordinates\n",
    "            x -= left\n",
    "            y -= top\n",
    "            # Ensure coordinates are within the new image dimensions\n",
    "            x = max(0, min(x, right - left))\n",
    "            y = max(0, min(y, bottom - top))\n",
    "            adjusted_segment.extend([x, y])\n",
    "        new_segmentation.append(adjusted_segment)\n",
    "    annotation['segmentation'] = new_segmentation\n",
    "\n",
    "    new_width =  right - left\n",
    "    new_height = bottom - top\n",
    "    return annotation,new_height,new_width\n",
    "\n",
    "\n",
    "def process_dataset(annotations, images, output_folder, dataset_name,h,w,js_path):\n",
    "    \"\"\"\n",
    "    处理每个数据集，通过裁剪图像和更新标注。\n",
    "    此函数是此项目特定需求的数据集的核心。\n",
    "\n",
    "    参数:\n",
    "        annotations (list): 图像的注释列表。\n",
    "        images (list): 图像数据列表。\n",
    "        output_folder (str): 已处理图像和注释的目录。\n",
    "        dataset_name (str): 数据集名称。\n",
    "        h (int): 图像高度。\n",
    "        w (int): 图像宽度。\n",
    "        js_path (str): 对应JSON文件的路径。\n",
    "\n",
    "    返回:\n",
    "        tuple: 已处理的图像和更新的注释。\n",
    "\n",
    "    详细信息:\n",
    "    对于数据集中的每个注释，此功能查找相应的图像，应用 `crop_img` 函数，\n",
    "    并更新注释。它确保每个图像只处理一次，并编译已处理图像和其新注释的列表。\n",
    "    \"\"\"\n",
    "    # Dictionary to hold updated annotations\n",
    "    updated_annotations = []\n",
    "    # Set to track processed image ids\n",
    "    processed_image_ids = set()\n",
    "\n",
    "    # Process each annotation\n",
    "    for annotation in annotations:\n",
    "        if 'segmentation' in annotation and annotation['segmentation']:\n",
    "            image_id = annotation['image_id']\n",
    "            s1 = rle2polygon(annotation['segmentation'],h,w)\n",
    "            # Find the corresponding image\n",
    "            image_data = next((img for img in images if img['id'] == image_id), None)\n",
    "            if image_data:\n",
    "                image_path = os.path.join(dataset_name, image_data['file_name'])\n",
    "                # !!!NOTE:如果有相同图片名，需要自定义数据集名字!!!\n",
    "                new_dataset_name = js_path.split('\\\\')[5]\n",
    "                new_image_filename = new_dataset_name+'_'+image_data['file_name']\n",
    "                image_data['file_name'] =new_image_filename\n",
    "                updated_annotation,new_height,new_width = crop_img(\n",
    "                    image_path, output_folder, new_dataset_name, annotation,s1)\n",
    "                updated_annotations.append(updated_annotation)\n",
    "                image_data['height'] = new_height\n",
    "                image_data['width'] = new_width\n",
    "                processed_image_ids.add(image_id)\n",
    "\n",
    "    # Filter images to include only those that were processed\n",
    "    filtered_images = [img for img in images if img['id'] in processed_image_ids]\n",
    "\n",
    "    return filtered_images, updated_annotations\n",
    "\n",
    "\n",
    "def coco_to_yolo(coco_file_path, output_dir):\n",
    "    \"\"\"\n",
    "    将COCO格式的注释转换为YOLO格式, 适用于不同类型的对象检测模型。\n",
    "\n",
    "    参数:\n",
    "        coco_file_path (str): COCO格式文件的路径。\n",
    "        output_dir (str): 保存YOLO格式注释的目录。\n",
    "\n",
    "    详细信息:\n",
    "    此功能读取COCO数据集, 迭代其注释, 并将每个注释转换为YOLO格式。\n",
    "    它为每个图像创建一个文本文件, 其中每行对应一个以YOLO格式表示的对象。\n",
    "    该函数考虑图像尺寸以标准化边界框的坐标。\n",
    "    \"\"\"\n",
    "    # Load the COCO data\n",
    "    with open(coco_file_path, \"r\", encoding='utf-8') as file:\n",
    "        coco_data = json.load(file)\n",
    "\n",
    "    # Create a directory to store the YOLO formatted annotations\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Create a mapping from image id to file name and its dimensions for easy access\n",
    "    image_id_to_info = {img[\"id\"]: (img[\"file_name\"], img[\"width\"], img[\"height\"]) for img in coco_data[\"images\"]}\n",
    "\n",
    "    # Create a mapping from category id to category index\n",
    "    category_id_to_index = {cat[\"id\"]: idx for idx, cat in enumerate(coco_data[\"categories\"])}\n",
    "\n",
    "    # Iterate over each annotation and save in YOLO format\n",
    "    for annotation in tqdm(coco_data[\"annotations\"], desc=\"Converting annotations\"):\n",
    "        # Get file name, width, and height for the annotation's image\n",
    "        image_filename, img_width, img_height = image_id_to_info[annotation[\"image_id\"]]\n",
    "        txt_filename = os.path.splitext(image_filename)[0] + \".txt\"\n",
    "        txt_filepath = os.path.join(output_dir, txt_filename)\n",
    "        \n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(txt_filepath):\n",
    "            print(f\"File already exists: {txt_filepath}\")\n",
    "\n",
    "        # Get the class index for the annotation\n",
    "        class_index = category_id_to_index[annotation[\"category_id\"]]\n",
    "\n",
    "        # Normalize segmentation points\n",
    "        normalized_points = []\n",
    "        segmentation = annotation[\"segmentation\"][0]  # Assuming each annotation has one segmentation\n",
    "        for i in range(0, len(segmentation), 2):\n",
    "            normalized_x = segmentation[i] / img_width\n",
    "            normalized_y = segmentation[i + 1] / img_height\n",
    "            normalized_points.extend([normalized_x, normalized_y])\n",
    "\n",
    "        # Write to the txt file\n",
    "        with open(txt_filepath, \"a\") as file:\n",
    "            file.write(f\"{class_index} {' '.join(map(str, normalized_points))}\\n\")\n",
    "\n",
    "# Function to create a new dataset\n",
    "def create_new_dataset(original_dataset, processed_images, processed_annotations):\n",
    "    return {\n",
    "        \"info\": original_dataset.get(\"info\", {}),\n",
    "        \"licenses\": original_dataset.get(\"licenses\", []),\n",
    "        \"categories\": original_dataset.get(\"categories\", []),\n",
    "        \"images\": processed_images,\n",
    "        \"annotations\": processed_annotations\n",
    "    }\n",
    "\n",
    "def setup_directories(output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    else:\n",
    "        shutil.rmtree(output_folder)\n",
    "        os.makedirs(output_folder)\n",
    "    if not os.path.exists(os.path.join(output_folder, 'images')):\n",
    "        os.makedirs(os.path.join(output_folder, 'images'))\n",
    "    if not os.path.exists(os.path.join(output_folder, 'labels')):\n",
    "        os.makedirs(os.path.join(output_folder, 'labels'))\n",
    "\n",
    "def get_dataset_name(js_path):\n",
    "    return js_path.split('\\\\')[5]\n",
    "\n",
    "def load_dataset(js_path):\n",
    "    with open(js_path, encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset, dataset['images'], dataset['annotations']\n",
    "\n",
    "def get_image_dimensions(images):\n",
    "    if images:\n",
    "        return images[0]['height'], images[0]['width']\n",
    "    return 0, 0\n",
    "\n",
    "def save_new_dataset(dataset, output_folder, dataset_name):\n",
    "    tmp_path = os.path.join(output_folder, 'tmp')\n",
    "    if not os.path.exists(tmp_path):\n",
    "        os.makedirs(tmp_path)\n",
    "    else:\n",
    "        shutil.rmtree(tmp_path)\n",
    "        os.makedirs(tmp_path)\n",
    "    output_file = os.path.join(tmp_path, f'{dataset_name}_processed.json')\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=4)\n",
    "    return output_file\n",
    "\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # Step1: 设置image和对应json的路径名\n",
    "    json_files = [r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230811_110050\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230810_092218\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230802_103503\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230728_092252\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230728_083801\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230714_123805\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230713_092647\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230714_113213\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230714_104658\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230714_093927\\annotations\\instances_default.json',\n",
    "                  r'C:\\Users\\z8443\\Downloads\\手术器械标注\\20230713_103330\\annotations\\instances_default.json',\n",
    "                  ]\n",
    "    image_files = [r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230811_110050',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230810_092218',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230802_103503',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230728_092252',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230728_083801',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230714_123805',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230713_092647',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230714_113213',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230714_104658',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230714_093927',\n",
    "                    r'C:\\Users\\z8443\\Downloads\\pic\\TV_CAM_device_20230713_103330',\n",
    "                    ]\n",
    "    \n",
    "    # 自定义新的数据集名\n",
    "    output_folder = 'new_dataset'\n",
    "    setup_directories(output_folder)\n",
    "    \n",
    "    # Step2: 针对每一个json和对应的image：1.进行图片裁剪 2.rle_mask坐标转换为coco\n",
    "    for js_path, dataset_name in zip(json_files, image_files):\n",
    "        new_dataset_name = get_dataset_name(js_path)\n",
    "        original_dataset, images, annotations = load_dataset(js_path)\n",
    "        h, w = get_image_dimensions(images)\n",
    "\n",
    "        processed_images, processed_annotations = process_dataset(\n",
    "            annotations, images, output_folder, dataset_name, h, w,js_path)\n",
    "\n",
    "        new_dataset = create_new_dataset(\n",
    "            original_dataset, processed_images, processed_annotations)\n",
    "\n",
    "        coco_json_path = save_new_dataset(new_dataset, output_folder, new_dataset_name)\n",
    "        \n",
    "        # Step3: 将coco格式的标注转换为yolo格式\n",
    "        coco_to_yolo(coco_json_path, os.path.join(output_folder, 'labels'))\n",
    "        shutil.rmtree(os.path.join(output_folder, 'tmp'))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVAT的COCO数据到YOLO格式转换\n",
    "\n",
    "## 描述\n",
    "此脚本用于处理图像数据集，以用于对象检测任务。它涉及裁剪图像、调整尺寸、调整注释，并将数据集从COCO格式转换为YOLO格式以进行训练。\n",
    "\n",
    "## 工作流程\n",
    "1. 加载所需的JSON和图像文件。\n",
    "2. 创建处理数据的必要目录。\n",
    "3. 处理每个JSON文件：裁剪图像，调整图像尺寸和注释。\n",
    "4. 以COCO格式保存处理后的数据。\n",
    "5. 将COCO格式数据转换为YOLO格式，以进行进一步的训练。\n",
    "\n",
    "## 功能\n",
    "- `rle2polygon`: 将RLE或多边形分割数据转换为多边形坐标。\n",
    "- `crop_img`: 裁剪图像并调整其注释。\n",
    "- `process_dataset`: 处理每个数据集，更新注释和图像。\n",
    "- `create_new_dataset`: 使用处理过的数据创建一个新数据集。\n",
    "- `coco_to_yolo`: 将COCO格式注释转换为YOLO格式。\n",
    "\n",
    "## 使用方法\n",
    "在设置好 `json_files` 和 `image_files` 列表与数据集路径后，运行脚本。确保所有依赖都已安装并正确设置路径。\n",
    "\n",
    "## 依赖\n",
    "- Python 3.x\n",
    "- 库：shutil, os, json, cv2, PIL, pycocotools\n",
    "\n",
    "## 注意事项\n",
    "- 根据需要自定义裁剪坐标和其他参数。\n",
    "- 确保已安装正确的Python版本和依赖。\n",
    "- 脚本假设JSON文件路径具有特定结构，以提取数据集名称。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
